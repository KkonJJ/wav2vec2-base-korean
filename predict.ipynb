{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Korean Speech Recognition using Wav2Vec2 Model\n",
    "This notebook demonstrates how to use the pre-trained Wav2Vec2 model from Hugging Face to convert Korean speech to text."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Import necessary libraries\n",
    "import torch\n",
    "from transformers import Wav2Vec2ForCTC, Wav2Vec2Processor\n",
    "import torchaudio\n",
    "from jamo import h2j, j2hcj, is_jamo"
   ],
   "execution_count": 1,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Model and Processor\n",
    "Load the pre-trained Wav2Vec2 model and processor from the Hugging Face Hub."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Load the model and processor\n",
    "model_name = \"Kkonjeong/wav2vec2-base-korean\"\n",
    "processor = Wav2Vec2Processor.from_pretrained(model_name)\n",
    "model = Wav2Vec2ForCTC.from_pretrained(model_name)\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "model.eval()\n",
    "model.to(\"cuda\")"
   ],
   "execution_count": 2,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jamo Combination Function\n",
    "Define a function to combine Jamo characters into complete Hangul text."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Function to combine Jamo characters\n",
    "def combine_jamo(jamo_text):\n",
    "    hangul_text = \"\"\n",
    "    buffer = []\n",
    "\n",
    "    # Function to validate Jamo characters\n",
    "    def is_valid_jamo(jamo):\n",
    "        return 0x1100 <= ord(jamo) <= 0x11FF\n",
    "\n",
    "    def flush_buffer(buffer):\n",
    "        if len(buffer) == 3:\n",
    "            initial = ord(buffer[0]) - 0x1100\n",
    "            medial = ord(buffer[1]) - 0x1161\n",
    "            final = ord(buffer[2]) - 0x11A7\n",
    "            if (0 <= initial < 19) and (0 <= medial < 21) and (0 <= final < 28):\n",
    "                return chr(0xAC00 + initial * 588 + medial * 28 + final)\n",
    "        elif len(buffer) == 2:\n",
    "            initial = ord(buffer[0]) - 0x1100\n",
    "            medial = ord(buffer[1]) - 0x1161\n",
    "            if (0 <= initial < 19) and (0 <= medial < 21):\n",
    "                return chr(0xAC00 + initial * 588 + medial * 28)\n",
    "        elif len(buffer) == 1:\n",
    "            return buffer[0]\n",
    "        return ''.join(buffer)\n",
    "\n",
    "    for jamo in jamo_text:\n",
    "        if is_jamo(jamo) and is_valid_jamo(jamo):\n",
    "            buffer.append(jamo)\n",
    "            if len(buffer) == 3:\n",
    "                hangul_text += flush_buffer(buffer)\n",
    "                buffer = []\n",
    "        else:\n",
    "            hangul_text += flush_buffer(buffer)\n",
    "            hangul_text += jamo\n",
    "            buffer = []\n",
    "\n",
    "    if buffer:\n",
    "        hangul_text += flush_buffer(buffer)\n",
    "\n",
    "    return hangul_text"
   ],
   "execution_count": 3,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Speech-to-Text Prediction Function\n",
    "Define a function to perform inference on an audio file and predict the text."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Function to perform inference on an audio file and predict the text\n",
    "def predict_from_audio(audio_path):\n",
    "    # Load the audio file\n",
    "    speech_array, sampling_rate = torchaudio.load(audio_path)\n",
    "\n",
    "    # Resample if the sampling rate is not 16000Hz\n",
    "    if sampling_rate != 16000:\n",
    "        resampler = torchaudio.transforms.Resample(orig_freq=sampling_rate, new_freq=16000)\n",
    "        speech_array = resampler(speech_array)\n",
    "\n",
    "    # Convert to 2D tensor\n",
    "    speech_array = speech_array.squeeze().numpy()\n",
    "\n",
    "    # Preprocess the audio file\n",
    "    input_values = processor(speech_array, sampling_rate=16000, return_tensors=\"pt\").input_values\n",
    "    input_values = input_values.to(\"cuda\")\n",
    "\n",
    "    # Perform inference\n",
    "    with torch.no_grad():\n",
    "        logits = model(input_values).logits\n",
    "\n",
    "    # Decode the Jamo text\n",
    "    pred_ids = torch.argmax(logits, dim=-1)\n",
    "    jamo_text = processor.batch_decode(pred_ids)[0]\n",
    "\n",
    "    # Combine the Jamo text to form the final sentence\n",
    "    final_text = combine_jamo(jamo_text)\n",
    "\n",
    "    return final_text"
   ],
   "execution_count": 4,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example: Predicting Text from an Audio File\n",
    "Use the specified audio file to predict the text."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Example: Predicting text from an audio file\n",
    "audio_path = \"jiwon_.wav\"\n",
    "predicted_text = predict_from_audio(audio_path)\n",
    "print(\"Predicted Text: \", predicted_text)"
   ],
   "execution_count": 5,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Predicted Text:  Example text\n"
     ],
     "name": "stdout"
    }
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
